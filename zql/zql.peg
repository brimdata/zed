#define DQUOTE \x22
#define SQUOTE \x27

#ifdef GO
{
    package zql
}
#define RETURN(x) return x, nil
#define VAR(x) var x
#define NULL nil
#define ARRAY(...) []interface{}{__VA_ARGS__}
#define ARRAY_LEN(a) len(a.([]interface{}))
#define FOREACH(arr, var) for _, var := range arr
#define APPEND(arr, value) arr = append(arr, value)
#define PREPEND(value, arr) append([]interface{}{value}, (arr.([]interface{}))...)
#define TEXT string(c.text)
#define TOSTRING(s) fmt.Sprintf("%v", s)
#define ISNOTNULL(n) n != nil
#define ASSERT_ARRAY(a) a.([]interface{})
#define ASSERT_STRING(s) s.(string)
#define ASSERT_INT(i) i.(int)
#define ASSERT_MAP(m) m.(map[string]interface{})
#define HAS(m, k) _, ok := m[k]; ok
#define MAP(...) map[string]interface{}{__VA_ARGS__}
#define PRINT(...) fmt.Println(__VA_ARGS__)
#else
{
#include "parser-support.js"
}
#define RETURN(x) return x
#define VAR(x) let x
#define NULL null
#define ARRAY(...) [__VA_ARGS__]
#define ARRAY_LEN(a) a.length
#define FOREACH(arr, var) for(let var of arr)
#define APPEND(arr, value) arr.push(value)
#define PREPEND(value, arr) [value, ...arr]
#define TEXT text()
#define ASSERT_INT(i) i
#define TOSTRING(s) s.toString()
#define ISNOTNULL(n) (n)
#define ASSERT_ARRAY(a) a
#define ASSERT_STRING(s) s
#define ASSERT_MAP(m) m
#define HAS(m, k) (k in m)
#define MAP(...) {__VA_ARGS__}
#define PRINT(...) console.log(__VAR_ARGS__)
#endif

start = __ ast:Query __ EOF { RETURN(ast) }

Query
  = procs:SequentialProcs {
      RETURN(MAP("op": "SequentialProc", "procs": procs))
    }
  / s:Search __ rest:SequentialTail* {
      if (ARRAY_LEN(rest) == 0) {
          RETURN(s)
      } else {
          RETURN(MAP("op": "SequentialProc", "procs": PREPEND(s, rest)))
      }
    }

Search
  = expr:SearchExpr {
      RETURN(MAP("op": "FilterProc", "filter": expr))
    }

SearchExpr
  = first:SearchTerm rest:OredSearchTerm* {
      RETURN(makeChain(first, rest, "LogicalOr"))
    }

OredSearchTerm = _ OrToken _ t:SearchTerm { RETURN(t) }

SearchTerm
  = first:SearchFactor rest:AndedSearchTerm* {
      RETURN(makeChain(first, rest, "LogicalAnd"))
    }

AndedSearchTerm = _ (AndToken _)? f:SearchFactor { RETURN(f) }

SearchFactor
  = (NotToken _ / "!" __) e:SearchExpr {
      RETURN(MAP("op": "LogicalNot", "expr": e))
    }
  / !("-") s:SearchPred { RETURN(s) }
  / "(" __ expr:SearchExpr __ ")" { RETURN(expr) }

SearchPred
  = "*" __ comp:EqualityToken __ v:SearchValue {
      RETURN(MAP("op": "CompareAny", "comparator": comp, "recursive": false, "value": v))
    }
  / "**" __ comp:EqualityToken __ v:SearchValue {
      RETURN(MAP("op": "CompareAny", "comparator": comp, "recursive": true, "value": v))
    }
  / f:Lval __ comp:EqualityToken __ v:SearchValue {
      RETURN(MAP("op": "CompareField", "comparator": comp, "field": f, "value": v))
    }
  // XXX this is here for now to let "len(array)" be matched now that we have
  // made reducer names generic (which will be far easier to add to and maintain),
  // and a better fix awaits the language tweaks coming in issue #1371.  At that
  // point this peg rule will be subsumed by a unified search/expression syntax.
  / &"len" expr:Function __ comp:EqualityToken __ v:SearchValue {
    RETURN(MAP("op": "BinaryExpression", "operator": comp, "lhs": expr, "rhs": v))
  }
  / v:SearchValue __ InToken __ "*" {
      RETURN(MAP("op": "CompareAny", "comparator": "in", "recursive": false, "value": v))
    }
  / v:SearchValue __ InToken __ f:FieldExpr {
      RETURN(MAP("op": "CompareField", "comparator": "in", "field": f, "value": v))
    }
  / v:SearchLiteral {
      RETURN(MAP("op": "Search", "text": TEXT, "value": v))
    }
  / !(SearchTokens _ ) v:KeyWord {
      VAR(str) = ASSERT_STRING(v)
      if (str == "*") {
        RETURN(MAP("op": "MatchAll"))
      }
      VAR(literal) = MAP("op": "Literal", "type": "string", "value": v)
      if (reglob.IsGlobby(str)) {
        literal["type"] = "regexp"
        literal["value"] = reglob.Reglob(str)
      }
      RETURN(MAP("op": "Search", "text": TEXT, "value": literal))
    }

SearchValue
  = SearchLiteral
  / !(SearchTokens _) v:KeyWord {
      RETURN(MAP("op": "Literal", "type": "string", "value": v))
    }

SearchTokens
  = AndToken
  / OrToken
  / InToken

SearchLiteral
  = StringLiteral
  / RegexpLiteral
  / SubnetLiteral
  / AddressLiteral
  / FloatLiteral

  // Careful not to use IntegerLiteral unconditionally or it will consume
  // the beginning of something like 1234abcd which is a valid search word
  / i:IntegerLiteral !KeyWord { RETURN(i) }

  / !(SearchTokens _) v:BooleanLiteral { RETURN(v) }
  / !(SearchTokens _) v:NullLiteral { RETURN(v) }


StringLiteral
  = v:QuotedString {
      RETURN(MAP("op": "Literal", "type": "string", "value": v))
    }

RegexpLiteral
  = v:Regexp {
      RETURN(MAP("op": "Literal", "type": "regexp", "value": v))
    }

SubnetLiteral
  = v:IP6Net !IdentifierRest {
      RETURN(MAP("op": "Literal", "type": "net", "value": v))
    }
  / v:IP4Net {
      RETURN(MAP("op": "Literal", "type": "net", "value": v))
    }

AddressLiteral
  = v:IP6 !IdentifierRest {
      RETURN(MAP("op": "Literal", "type": "ip", "value": v))
    }
  / v:IP {
      RETURN(MAP("op": "Literal", "type": "ip", "value": v))
    }

FloatLiteral
  = v:FloatString {
      RETURN(MAP("op": "Literal", "type": "float64", "value": v))
    }

IntegerLiteral
  = v:IntString {
      RETURN(MAP("op": "Literal", "type": "int64", "value": v))
    }

BooleanLiteral
  = "true"           { RETURN(MAP("op": "Literal", "type": "bool", "value": "true")) }
  / "false"          { RETURN(MAP("op": "Literal", "type": "bool", "value": "false")) }

NullLiteral
  = "null"           { RETURN(MAP("op": "Literal", "type": "null", "value": "")) }

SequentialProcs
  = first:Proc rest:SequentialTail* {
     if ISNOTNULL(rest) {
        RETURN(PREPEND(first, rest))
      }
      RETURN(ARRAY(first))
    }

SequentialTail = __ "|" __ p:Proc { RETURN(p) }

Proc
  = NamedProc
  / "split" __ "(" __ "=>" __ proc:Procs __ ")" {
      RETURN(proc)
    }
  / GroupByProc

Procs
  = first:SequentialProcs rest:ParallelTail* {
      VAR(fp) = MAP("op": "SequentialProc", "procs": first)
      if ISNOTNULL(rest) {
        RETURN(MAP("op": "ParallelProc", "procs": PREPEND(fp, rest)))
      } else {
        RETURN(fp)
      }
    }

ParallelTail
  = __ ";"? __ "=>" __ ch:SequentialProcs { RETURN(MAP("op": "SequentialProc", "procs": ch)) }

GroupByProc
  = every:EveryDur? keys:GroupByKeys limit:LimitArg {
      RETURN(MAP("op": "GroupByProc", "keys": keys, "reducers": NULL, "duration": every, "limit": limit))
    }
  / every:EveryDur? reducers:Reducers keys:(_ GroupByKeys)? limit:LimitArg? {
      VAR(p) = MAP("op": "GroupByProc", "keys": NULL, "reducers": reducers, "duration": every, "limit": limit)
      if ISNOTNULL(keys) {
        p["keys"] = ASSERT_ARRAY(keys)[1]
      }
      RETURN(p)
    }

EveryDur
  = "every"i _ dur:Duration _ { RETURN(dur) }

GroupByKeys
  = "by"i _ columns:FlexAssignments { RETURN(columns) }

LimitArg
  = _ "with" _ "-limit" _ limit:UInt { RETURN(limit) }
  / "" { RETURN(0) }

// A FlexAssignment is like an Assignment but it can optionally omit the lhs,
// in which case the semantic pass will infer a name from the rhs, e.g., for
// an expression like "count() by foo", the rhs is Field "foo" and the lhs is nil.
FlexAssignment
  = Assignment
  / expr:Expr { RETURN(MAP("op": "Assignment", "lhs": NULL, "rhs": expr)) }

FlexAssignments
  = first:FlexAssignment rest:(__ "," __ expr:FlexAssignment { RETURN(expr) })* {
      RETURN(PREPEND(first, rest))
    }

ReducerAssignment
  = lval:Lval __ "=" __ reducer:Reducer {
      RETURN(MAP("op": "Assignment", "lhs": lval, "rhs": reducer))
    }
  / reducer:Reducer {
      RETURN(MAP("op": "Assignment", "lhs": NULL, "rhs": reducer))
    }

Reducer
  = !("not"/"len") op:IdentifierName __ "(" __ expr:Expr?  __ ")" where:WhereClause? {
      VAR(r) = MAP("op": "Reducer", "operator": op, "expr": NULL, "where":where)
      if ISNOTNULL(expr) {
        r["expr"] = expr
      }
      RETURN(r)
    }

WhereClause = _ "where" _ expr:Expr { RETURN(expr) }

Reducers
  = first:ReducerAssignment rest:(__ "," __ ReducerAssignment)* {
      VAR(result) = ARRAY(first)
      FOREACH(ASSERT_ARRAY(rest), r) {
        APPEND(result, ASSERT_ARRAY(r)[3])
      }
      RETURN(result)
    }

NamedProc
  = SortProc
  / TopProc
  / CutProc
  / PickProc
  / DropProc
  / HeadProc
  / TailProc
  / FilterProc
  / UniqProc
  / PutProc
  / RenameProc
  / FuseProc
  / JoinProc

SortProc
  = "sort"i args:SortArgs list:(_ l:Exprs { RETURN(l) })? {
      VAR(argm) = ASSERT_MAP(args)
      VAR(proc) = MAP("op": "SortProc", "fields": list, "sortdir": 1, "nullsfirst": false)
      if HAS(argm, "r") {
        proc["sortdir"] = -1
      }
      if HAS(argm, "nulls") {
        if (argm["nulls"] == "first") {
          proc["nullsfirst"] = true
        }
      }
      RETURN(proc)
    }

SortArgs = args:(_ a:SortArg{ RETURN(a) })* { return makeArgMap(args) }

SortArg
  = "-r" { RETURN(MAP("name": "r", "value": NULL)) }
  / "-nulls" _ where:(("first" / "last") { RETURN(TEXT) } ) { RETURN(MAP("name": "nulls", "value": where)) }

TopProc
  = "top"i limit:(_ n:UInt { RETURN(n)})? flush:(_ "-flush")? fields:(_ f:FieldExprs { RETURN(f) })? {
      VAR(proc) = MAP("op": "TopProc", "limit": 0, "fields": NULL, "flush": false)
      if ISNOTNULL(limit) {
        proc["limit"] = limit
      }
      if ISNOTNULL(fields) {
        proc["fields"] = fields
      }
      if ISNOTNULL(flush) {
        proc["flush"] = true
      }
      RETURN(proc)
    }

CutProc
  = "cut"i args:CutArgs _ columns:FlexAssignments {
      VAR(argm) = ASSERT_MAP(args)
      VAR(proc) = MAP("op": "CutProc", "fields": columns, "complement": false)
      if HAS(argm, "c") {
        proc["complement"] = true
      }
      RETURN(proc)
    }

CutArgs
  = args:(_ "-c" { RETURN(MAP("name": "c", "value": NULL)) })* {
      return makeArgMap(args)
    }

PickProc
  = "pick"i _ columns:FlexAssignments {
      RETURN(MAP("op": "PickProc", "fields": columns))
    }

DropProc
  = "drop"i _ columns:FieldExprs {
      RETURN(MAP("op": "DropProc", "fields": columns))
    }

HeadProc
  = "head"i _ count:UInt { RETURN(MAP("op": "HeadProc", "count": count)) }
  / "head"i { RETURN(MAP("op": "HeadProc", "count": 1)) }

TailProc
  = "tail"i _ count:UInt { RETURN(MAP("op": "TailProc", "count": count)) }
  / "tail"i { RETURN(MAP("op": "TailProc", "count": 1)) }

FilterProc
  = "filter"i _ expr:SearchExpr {
      RETURN(MAP("op": "FilterProc", "filter": expr))
    }

UniqProc
  = "uniq"i _ "-c" {
      RETURN(MAP("op": "UniqProc", "cflag": true))
    }
  / "uniq"i {
      RETURN(MAP("op": "UniqProc", "cflag": false))
    }

PutProc
  = "put"i _ columns:FlexAssignments {
      RETURN(MAP("op": "PutProc", "clauses": columns))
    }

RenameProc
  = "rename"i _ first:Assignment rest:(__ "," __ cl:Assignment { RETURN(cl) })* {
      RETURN(MAP("op": "RenameProc", "fields": PREPEND(first, rest)))
    }

FuseProc
  = "fuse"i {
      RETURN(MAP("op": "FuseProc"))
    }

JoinProc
  = "join"i _ leftKey:JoinKey __ "=" __ rightKey:JoinKey columns:(_ FlexAssignments)? {
      VAR(proc) = MAP("op": "JoinProc", "left_key": leftKey, "right_key": rightKey, "clauses": NULL)
      if ISNOTNULL(columns) {
        proc["clauses"] = ASSERT_ARRAY(columns)[1]
      }
      RETURN(proc)
    }
  / "join"i _ key:JoinKey columns:(_ FlexAssignments)? {
      VAR(proc) = MAP("op": "JoinProc", "left_key": key, "right_key": key, "clauses": NULL)
      if ISNOTNULL(columns) {
        proc["clauses"] = ASSERT_ARRAY(columns)[1]
      }
      RETURN(proc)
    }

JoinKey
  = Lval
  / "(" expr:Expr ")" { RETURN(expr) }

RootField
  = "."? !(BooleanLiteral / NullLiteral) field:Identifier { RETURN(MAP("op": "BinaryExpr", "operator":".", "lhs":MAP("op":"RootRecord"), "rhs": field)) }
  / "." !(Identifier)  { RETURN(MAP("op": "RootRecord")) }

Lval = DerefExpr

FieldExpr = Lval

FieldExprs
  = first:FieldExpr rest:(__ "," __ FieldExpr)* {
      VAR(result) = ARRAY(first)

      FOREACH(ASSERT_ARRAY(rest), r) {
        APPEND(result, ASSERT_ARRAY(r)[3])
      }

      RETURN(result)
    }

Exprs
  = first:Expr rest:(__ "," __ Expr)* {
      VAR(result) = ARRAY(first)

      FOREACH(ASSERT_ARRAY(rest), r) {
        APPEND(result, ASSERT_ARRAY(r)[3])
      }

      RETURN(result)
    }

Assignment
  = lhs:Lval __ "=" __ rhs:Expr { RETURN(MAP("op": "Assignment", "lhs": lhs, "rhs": rhs)) }

Expr = ConditionalExpr

ConditionalExpr
  = condition:LogicalOrExpr __ "?" __ thenClause:Expr __ ":" __ elseClause:Expr {
      RETURN(MAP("op": "ConditionalExpr", "condition": condition, "then": thenClause, "else": elseClause))
    }
  / LogicalOrExpr

LogicalOrExpr
  = first:LogicalAndExpr
    rest:(__ op:OrToken __ expr:LogicalAndExpr{ RETURN(ARRAY(op, expr)) })* {
        RETURN(makeBinaryExprChain(first, rest))
    }

LogicalAndExpr
  = first:EqualityCompareExpr
    rest:(__ op:AndToken __ expr:EqualityCompareExpr{ RETURN(ARRAY(op, expr)) })* {
        RETURN(makeBinaryExprChain(first, rest))
    }

EqualityCompareExpr
  = first:RelativeExpr
    rest:(__ comp:EqualityComparator __ expr:RelativeExpr{ RETURN(ARRAY(comp, expr)) })* {
        RETURN(makeBinaryExprChain(first, rest))
    }

EqualityOperator = ("=~" / "!~" / "=" / "!=") { RETURN(TEXT) }

EqualityComparator
  = EqualityOperator
  / "in" { RETURN(TEXT) }

RelativeExpr
  = first:AdditiveExpr
    rest:(__ op:RelativeOperator __ expr:AdditiveExpr{ RETURN(ARRAY(op, expr)) })* {
        RETURN(makeBinaryExprChain(first, rest))
    }

RelativeOperator = ("<=" / "<" / ">=" / ">") { RETURN(TEXT) }

AdditiveExpr
  = first:MultiplicativeExpr
    rest:(__ op:AdditiveOperator __ expr:MultiplicativeExpr{ RETURN(ARRAY(op, expr)) })* {
        RETURN(makeBinaryExprChain(first, rest))
    }

AdditiveOperator = ("+" / "-") { RETURN(TEXT) }

MultiplicativeExpr
  = first:NotExpr
    rest:(__ op:MultiplicativeOperator __ expr:NotExpr{ RETURN(ARRAY(op, expr)) })* {
        RETURN(makeBinaryExprChain(first, rest))
    }

MultiplicativeOperator = ("*" / "/") { RETURN(TEXT) }

NotExpr
  = "!" __ e:NotExpr {
        RETURN(MAP("op": "UnaryExpr", "operator": "!", "operand": e))
    }
  / CastExpr

CastExpr
  = e:FuncExpr typ:( ":" typ:PrimitiveType { RETURN(typ) }) {
      RETURN(MAP("op": "CastExpr", "expr": e, "type": typ))
    }
  / FuncExpr


PrimitiveType
  = (   "bytes" / "uint8" / "uint16" / "uint32" / "uint64"
      / "int8" / "int16" / "int32" / "int64"
      / "duration" / "time"
      / "float64"
      / "bool" / "bytes" / "string" / "bstring"
      / "ip" / "net"
      / "type" / "error" / "null" ) { RETURN(TEXT) }

FuncExpr
  = first:Function rest:(Deref)* {
      RETURN(makeBinaryExprChain(first, rest))
    }
  / DerefExpr
  / Primary

Function
  = fn:DeprecatedName __ "(" args:ArgumentList ")" {
      RETURN(MAP("op": "FunctionCall", "function": fn, "args": args))
    }

//XXX change Function names to IdentifierName once we completely
// get rid of deprecated package-style function name errors.
DeprecatedName = IdentifierStart (IdentifierRest / ".")* { RETURN(TEXT) }

ArgumentList
  = first:Expr rest:(__ "," __ e:Expr { RETURN(e) })* {
      RETURN(PREPEND(first, rest))
    }
  / __ { RETURN(ARRAY()) }

DerefExpr
  = first:RootField rest:(Deref)* {
      RETURN(makeBinaryExprChain(first, rest))
    }

Deref
  = "[" expr:Expr "]" { RETURN(ARRAY("[", expr)) }
  / "." !(".") id:Identifier { RETURN(ARRAY(".", id)) }

Primary
  = StringLiteral
  / RegexpLiteral
  / SubnetLiteral
  / AddressLiteral
  / FloatLiteral
  / IntegerLiteral
  / BooleanLiteral
  / NullLiteral
  / "(" __ expr:Expr __ ")" { RETURN(expr) }

EqualityToken
  = EqualityOperator / RelativeOperator

AndToken = "and"i { RETURN(TEXT) }
OrToken = "or"i { RETURN(TEXT) }
InToken = "in"i { RETURN(TEXT) }
NotToken = "not"i { RETURN(TEXT) }

IdentifierName = IdentifierStart IdentifierRest* { RETURN(TEXT) }

IdentifierStart = [A-Za-z_$]
IdentifierRest = IdentifierStart / [0-9]

Identifier
  = IdentifierStart IdentifierRest* { RETURN(MAP("op": "Identifier", "name": TEXT)) }

Duration
  = Seconds
  / Minutes
  / Hours
  / Hours _ "and" _ Minutes
  / Days
  / Weeks

SecondsToken
  = "seconds"
  / "second"
  / "secs"
  / "sec"
  / "s"

MinutesToken
  = "minutes"
  / "minute"
  / "mins"
  / "min"
  / "m"

HoursToken
  = "hours"
  / "hrs"
  / "hr"
  / "h"
  / "hour"

DaysToken = "days"/"day"/"d"
WeeksToken = "weeks"/"week"/"wks"/"wk"/"w"

Seconds
  = "second" { RETURN(MAP("type": "Duration", "seconds": 1)) }
  / num:UInt __ SecondsToken { RETURN(MAP("type": "Duration", "seconds": num)) }

Minutes
  = "minute" { RETURN(MAP("type": "Duration", "seconds": 60)) }
  / num:UInt __ MinutesToken { RETURN(MAP("type": "Duration", "seconds": ASSERT_INT(num)*60)) }

Hours
  = "hour" { RETURN(MAP("type": "Duration", "seconds": 3600)) }
  / num:UInt __ HoursToken { RETURN(MAP("type": "Duration", "seconds": ASSERT_INT(num)*3600)) }

Days
  = "day" { RETURN(MAP("type": "Duration", "seconds": 3600*24)) }
  / num:UInt __ DaysToken { RETURN(MAP("type": "Duration", "seconds": (ASSERT_INT(num)*3600*24))) }

Weeks
  = "week" { RETURN(MAP("type": "Duration", "seconds": 3600*24*7)) }
  / num:UInt __ WeeksToken { RETURN(MAP("type": "Duration", "seconds": ASSERT_INT(num)*3600*24*7)) }

//XXX what about mac addrs?
IP
  = UInt "." UInt "." UInt "." UInt { RETURN(TEXT) }

// this matches a superset of legal syntax for ip6 addresses but the compiler
// will catch any errors when translating the filter
IP6
  = a:HexColon+ b:IP6Tail {
      RETURN(joinChars(a) + ASSERT_STRING(b))
    }
  / a:Hex b:ColonHex* "::" d:HexColon* e:IP6Tail {
      RETURN(ASSERT_STRING(a) + joinChars(b) + "::" + joinChars(d) + ASSERT_STRING(e))
    }
  / "::" a:HexColon* b:IP6Tail {
      RETURN("::" + joinChars(a) + ASSERT_STRING(b))
    }
  / a:Hex b:ColonHex* "::" {
      RETURN(ASSERT_STRING(a) + joinChars(b) + "::")
    }
  / "::" {
      RETURN("::")
    }

IP6Tail
  = IP
  / Hex

ColonHex = ":" v:Hex { RETURN(":" + ASSERT_STRING(v)) }
HexColon = v:Hex ":" { RETURN(ASSERT_STRING(v) + ":") }

IP4Net
  = a:IP '/' m:UInt {
      RETURN(ASSERT_STRING(a) + "/" + TOSTRING(m));
    }

IP6Net
  = a:IP6 '/' m:UInt {
      RETURN(ASSERT_STRING(a) + "/" + ASSERT_STRING(m));
    }

UInt
 = s:UIntString { RETURN(parseInt(s)) }

IntString
  = UIntString
  / MinusIntString

UIntString = [0-9]+ { RETURN(TEXT) }

MinusIntString
  = "-" UIntString { RETURN(TEXT) }

FloatString
  = "-"? [0-9]+ "." [0-9]+ ExponentPart? {
      RETURN(TEXT)
    }
  / "-"? "." [0-9]+ ExponentPart? {
      RETURN(TEXT)
    }

ExponentPart = "e"i [+-]? UIntString

Hex = HexDigit+ { RETURN(TEXT) }

HexDigit = [0-9a-fA-F]

KeyWord
  = chars:KeyWordPart+ { RETURN(joinChars(chars)) }

KeyWordPart
  = "\\" s:(EscapeSequence / SearchEscape)  { RETURN(s) }
  / !([\x00-\x1F\x5C(),!><=DQUOTE|SQUOTE;:] / WhiteSpace) . { RETURN(TEXT) }

QuotedString
  = '"' v:DoubleQuotedChar* '"' { RETURN(joinChars(v)) }
  / "'" v:SingleQuotedChar* "'" { RETURN(joinChars(v)) }

DoubleQuotedChar
  = !('"' / EscapedChar) . { RETURN(TEXT) }
  / "\\" s:EscapeSequence { RETURN(s) }

SingleQuotedChar
  = !("'" / EscapedChar) . { RETURN(TEXT) }
  / "\\" s:EscapeSequence { RETURN(s) }

EscapeSequence
  = "x" HexDigit HexDigit { RETURN("\\" + TEXT) }
  / SingleCharEscape
  / UnicodeEscape

SingleCharEscape
  = "'"
  / '"'
  / "\\"
  / "b" { RETURN("\b") }
  / "f" { RETURN("\f") }
  / "n" { RETURN("\n") }
  / "r" { RETURN("\r") }
  / "t" { RETURN("\t") }
  / "v" { RETURN("\v") }

SearchEscape
  = "=" { RETURN("=") }
  / "*" { RETURN("\\*") }

UnicodeEscape
  = "u" chars:(HexDigit HexDigit HexDigit HexDigit) {
      RETURN(makeUnicodeChar(chars))
    }
  / "u" "{" chars:(HexDigit HexDigit? HexDigit? HexDigit? HexDigit? HexDigit?) "}" {
      RETURN(makeUnicodeChar(chars))
    }

Regexp
  = "/" body:RegexpBody "/" { RETURN(body) }

RegexpBody
  = ([^/\\]/"\\/")+ { RETURN(TEXT) }

EscapedChar
  = [\x00-\x1f\\]

_  = AnySpace+
__ = AnySpace*

AnySpace
  = WhiteSpace
  / LineTerminator
  / Comment

SourceCharacter
  = .

WhiteSpace "whitespace"
  = "\t"
  / "\v"
  / "\f"
  / " "
  / "\u00A0"
  / "\uFEFF"

LineTerminator
  = [\n\r\u2028\u2029]

// XXX We will leave multi-line comments out for now since there is some work
// that needs to be done disambiguating among KeyWord, Regexp, and "/*".
// We will tackle this in the search-expr branch that is changing the grammar
// to better mix together ad hoc keyword search with formal boolean expressions.
Comment "comment"
  // = MultiLineComment
  // / SingleLineComment
  = SingleLineComment

MultiLineComment
  = "/*" (!"*/" SourceCharacter)* "*/"

SingleLineComment
  = "//" (!LineTerminator SourceCharacter)*

EOF = !.
